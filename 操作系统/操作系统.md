#### 1. 进程与线程的概念，以及为什么要有进程线程，其中有什么区别，他们各自又是怎么同步的

**进程与线程基本概念：**

**进程**是对运行时程序的封装，是系统进行资源调度和分配的的基本单位，实现了操作系统的并发；

**线程**是进程的子任务，是CPU 调度和分派的基本单位，用于保证程序的实时性，实现进程内部的并发；线程是操作系统可识别的最小执行和调度单位。每个线程都独自占用一个虚拟处理器：独自的寄存器组，指令计数器和处理器状态。每个线程完成不同的任务，但是共享同一地址空间（也就是同样的动态内存，映射文件，目标代码等等），打开的文件队列和其他内核资源。

**区别：**

（1）一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程。线程依赖于进程而存在。

（２）进程在执行过程中拥有独立的内存单元，而多个线程共享进程的内存。（资源分配给进程，同一进程的所有线程共享该进程的所有资源。同一进程中的多个线程共享代码段（代码和常量），数据段（全局变量和静态变量），扩展段（堆存储）。但是每个线程拥有自己的栈段，栈段又叫运行时段，用来存放所有局部变量和临时变量。）

（３）进程是资源分配的最小单位，线程是CPU 调度的最小单位；

（４）系统开销： 由于在创建或撤消进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等。因此，操作系统所付出的开销将显著地大于在创建或撤消线程时的开销。类似地，在进行进程切换时，涉及到整个当前进程CPU 环境的保存以及新被调度运行的进程的CPU 环境的设置。而线程切换只须保存和设置少量寄存器的内容，并不涉及存储器管理方面的操作。可见，进程切换的开销也远大于线程切换的开销。

（５）通信：由于同一进程中的多个线程具有相同的地址空间，致使它们之间的同步和通信的实现，也变得比较容易。进程间通信IPC，线程间可以直接读写进程数据段（如全局变量）来进行通信——需要进程同步和互斥手段的辅助，以保证数据的一致性。在有的系统中，线程的切换、同步和通信都无须操作系统内核的干预

（６）进程编程调试简单可靠性高，但是创建销毁开销大；线程正相反，开销小，切换速度快，但是编程调试相对复杂。

（７）进程间不会相互影响；线程一个线程挂掉将导致整个进程挂掉;

（８）进程适应于多核、多机分布；线程适用于多核。

**进程间通信的方式：**

进程间通信主要包括管道、系统IPC（包括消息队列、信号量、信号、共享内存等）、以及套接字socket。

**（１）管道：**

管道主要包括无名管道和命名管道:管道可用于具有亲缘关系的父子进程间的通信，有名管道除了具有管道所具有的功能外，它还允许无亲缘关系进程间的通信

**普通管道PIPE：**

1)它是半双工的（即数据只能在一个方向上流动），具有固定的读端和写端

2)它只能用于具有亲缘关系的进程之间的通信（也是父子进程或者兄弟进程之间）

3)它可以看成是一种特殊的文件，对于它的读写也可以使用普通的read、write 等函数。但是它不是普通的文件，并不属于其他任何文件系统，并且只存在于内存中。

**命名管道FIFO：**

1)FIFO 可以在无关的进程之间交换数据

2)FIFO 有路径名与之相关联，它以一种特殊设备文件形式存在于文件系统中。

**（２）系统IPC：**

 **消息队列**

消息队列，是消息的链接表，存放在内核中。一个消息队列由一个标识符（即队列ID）来标记。(消息队列克服了信号传递信息少，管道只能承载无格式字节流以及缓冲区大小受限等特点)具有写权限得进程可以按照一定得规则向消息队列中添加新信息；对消息队列有读权限得进程则可以从消息队列中读取信息；

特点：

1)消息队列是面向记录的，其中的消息具有特定的格式以及特定的优先级。

2)消息队列独立于发送与接收进程。进程终止时，消息队列及其内容并不会被删除。

3)消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取。

**信号量semaphore**

信号量（semaphore）与已经介绍过的IPC 结构不同，它是一个计数器，可以用来控制多个进程对共享资源的访问。信号量用于实现进程间的互斥与同步，而不是用于存储进程间通信数据。

特点：

1)信号量用于进程间同步，若要在进程间传递数据需要结合共享内存。

2)信号量基于操作系统的PV 操作，程序对信号量的操作都是原子操作。

3)每次对信号量的PV 操作不仅限于对信号量值加1 或减1，而且可以加减任意正整数。

4)支持信号量组。

**信号signal**

信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。

**共享内存（Shared Memory）**

它使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据得更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等

特点：

1)共享内存是最快的一种IPC，因为进程是直接对内存进行存取

2)因为多个进程可以同时操作，所以需要进行同步

3)信号量+共享内存通常结合在一起使用，信号量用来同步对共享内存的访问

**（３）套接字SOCKET：**

socket 也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同主机之间的进程通信。

**线程间通信的方式:**

**（１）临界区**

通过多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问；

**（２）互斥量Synchronized/Lock**

采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问

**（３）信号量Semphare**

为控制具有有限数量的用户资源而设计的，它允许多个线程在同一时刻去访问同一个资源，但一般需要限制同一时刻访问此资源的最大线程数目。

**（４）事件(信号)，Wait/Notify**

通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作。

#### 2. Linux 虚拟地址空间

为了防止不同进程同一时刻在物理内存中运行而对物理内存的争夺和践踏，采用了虚拟内存。

虚拟内存技术使得不同进程在运行过程中，它所看到的是自己独自占有了当前系统的4G 内存。所有进程共享同一物理内存，每个进程只把自己目前需要的虚拟内存空间映射并存储到物理内存上。事实上，在每个进程创建加载时，内核只是为进程“创建”了虚拟内存的布局，具体就是初始化进程控制表中内存相关的链表，实际上并不立即就把虚拟内存对应位置的程序数据和代码（比如.text .data 段）拷贝到物理内存中，只是建立好虚拟内存和磁盘文件之间的映射就好（叫做存储器映射），等到运行到对应的程序时，才会通过缺页异常，来拷贝数据。还有进程运行过程中，要动态分配内存，比如malloc 时，也只是分配了虚拟内存，即为这块虚拟内存对应的页表项做相应设置，当进程真正访问到此数据时，才引发缺页异常。

请求分页系统、请求分段系统和请求段页式系统都是针对虚拟内存的，通过请求实现内存与外存的信息置换。

**虚拟内存的好处：**

（1）扩大地址空间；

（2）内存保护：每个进程运行在各自的虚拟内存地址空间，互相不能干扰对方。虚存还对特定的内存地址提供写保护，可以防止代码或数据被恶意篡改。

（3）公平内存分配。采用了虚存之后，每个进程都相当于有同样大小的虚存空间。

（4）当进程通信时，可采用虚存共享的方式实现。

（5）当不同的进程使用同样的代码时，比如库文件中的代码，物理内存中可以只存储一份这样的代码，不同的进程只需要把自己的虚拟内存映射过去就可以了，节省内存

（6）虚拟内存很适合在多道程序设计系统中使用，许多程序的片段同时保存在内存中。当一个程序等待它的一部分读入内存时，可以把CPU 交给另一个进程使用。在内存中可以保留多个进程，系统并发度提高

（7）在程序需要分配连续的内存空间的时候，只需要在虚拟内存空间分配连续空间，而不需要
实际物理内存的连续空间，可以利用碎片

**虚拟内存的代价：**

（1）虚存的管理需要建立很多数据结构，这些数据结构要占用额外的内存

（2）虚拟地址到物理地址的转换，增加了指令的执行时间。

（3）页面的换入换出需要磁盘I/O，这是很耗时的

（4）如果一页中只有一部分数据，会浪费内存。

#### 3. 操作系统中的程序的内存结构

![](\images\内存结构.png)

一个程序本质上都是由BSS 段、data 段、text 段三个组成的。可以看到一个可执行程序在存储（没有调入内存）时分为代码段、数据区和未初始化数据区三部分。

**BSS 段（未初始化数据区）**：通常用来存放程序中未初始化的全局变量和静态变量的一块内存区域。BSS 段属于静态分配，程序结束后静态变量资源由系统自动释放。

**数据段**：存放程序中已初始化的全局变量的一块内存区域。数据段也属于静态内存分配

**代码段**：存放程序执行代码的一块内存区域。这部分区域的大小在程序运行前就已经确定，并且内存区域属于只读。在代码段中，也有可能包含一些只读的常数变量

text 段和data 段在编译时已经分配了空间，而BSS 段并不占用可执行文件的大小，它是由链接器来获取内存的。

bss 段（未进行初始化的数据）的内容并不存放在磁盘上的程序文件中。其原因是内核在程序开始运行前将它们设置为0。需要存放在程序文件中的只有正文段和初始化数据段。

data 段（已经初始化的数据）则为数据分配空间，数据保存到目标文件中。数据段包含经过初始化的全局变量以及它们的值。BSS 段的大小从可执行文件中得到，然后链接器得到这个大小的内存块，紧跟在数据段的后面。当这个内存进入程序的地址空间后全部清零。包含数据段和BSS 段的整个区段此时通常称为数据区。

可执行程序在运行时又多出两个区域：栈区和堆区。

**栈区**：由编译器自动释放，存放函数的参数值、局部变量等。每当一个函数被调用时，该函数的返回类型和一些调用的信息被存放到栈中。然后这个被调用的函数再为他的自动变量和临时变量在栈上分配空间。每调用一个函数一个新的栈就会被使用。栈区是从高地址位向低地址位增长的，是一块连续的内存区域，最大容量是由系统预先定义好的，申请的栈空间超过这个界限时会提示溢出，用户能从栈中获取的空间较小。

**堆区**：用于动态分配内存，位于BSS 和栈中间的地址区域。由程序员申请分配和释放。堆是从低地址位向高地址位增长，采用链式存储结构。频繁的malloc/free 造成内存空间的不连续，产生碎片。当申请堆空间时库函数是按照一定的算法搜索可用的足够大的空间。因此堆的效率比栈要低的多。

#### 4. 操作系统中的缺页中断

malloc()和mmap()等内存分配函数，在分配时只是建立了进程虚拟地址空间，并没有分配虚拟内存对应的物理内存。当进程访问这些没有建立映射关系的虚拟内存时，处理器自动触发一个缺页异常。

缺页中断：在请求分页系统中，可以通过查询页表中的状态位来确定所要访问的页面是否存在于内存中。每当所要访问的页面不在内存是，会产生一次缺页中断，此时操作系统会根据页表中的外存地址在外存中找到所缺的一页，将其调入内存。

缺页本身是一种中断，与一般的中断一样，需要经过4 个处理步骤：

（1）保护CPU 现场

（2）分析中断原因

（3）转入缺页中断处理程序进行处理

（4）恢复CPU 现场，继续执行

但是缺页中断是由于所要访问的页面不存在于内存时，由硬件所产生的一种特殊的中断，因此，与一般的中断存在区别：

（1）在指令执行期间产生和处理缺页中断信号

（2）一条指令在执行期间，可能产生多次缺页中断

（3）缺页中断返回是，执行产生中断的一条指令，而一般的中断返回是，执行下一条指令。

#### 5. 内存溢出和内存泄漏

**1、内存溢出**（Memory OverFlow）

指程序申请内存时，没有足够的内存供申请者使用。内存溢出就是你要的内存空间超过了系统实际分配给你的空间，此时系统相当于没法满足你的需求，就会报内存溢出的错误。

内存溢出原因：

（1）内存中加载的数据量过于庞大，如一次从数据库取出过多数据

（2）集合类中有对对象的引用，使用完后未清空，使得不能回收

（3）代码中存在死循环或循环产生过多重复的对象实体

（4）使用的第三方软件中的BUG

（5）启动参数内存值设定的过小

**栈溢出概念：**

栈溢出指的是程序向栈中某个变量中写入的字节数超过了这个变量本身所申请的字节数，因而导致栈中与其相邻的变量的值被改变。

栈溢出的原因：

①. 局部数组过大。当函数内部的数组过大时，有可能导致堆栈溢出。局部变量是存储在栈中的，因此这个很好理解。解决这类问题的办法有两个，一是增大栈空间,二是改用动态分配，使用堆（heap）而不是栈（stack）。

②. 递归调用层次太多。递归函数在运行时会执行压栈操作，当压栈次数太多时，也会导致堆栈溢出。

③. 指针或数组越界。这种情况最常见，例如进行字符串拷贝，或处理用户输入等等。

**堆内存溢出**

堆溢出一般是由内存泄漏导致的，内存泄漏是指因为疏忽或错误造成程序未能释放已经不再使用的内存的情况，因而造成了内存的浪费。因此当要求分配的内存超出了系统能够提供的，系统无法满足需求，于是会产生内存溢出的问题。

堆溢出原因：

①. 对未成功分配的内存进行相关操作。解决办法：在使用内存之前检查指针是否为NULL。对于指针作函数参数的情况，在函数入口处要进行指针的入参判断。对于用malloc或new申请的内存，应该用if(p==NULL)或if(p!=NULL)进行防错处理；

② 内存分配成功，但是未初始化就使用该内存；

③ 内存分配成功且已经初始化，但操作越过了内存的边界。例如：对于数组操作，指针超过了数组的界限；

④ 使用free或delete 释放了内存后，没有将指针设置为NULL，产生"悬空指针"。

**2、内存泄漏**（Memory Leak）

内存泄漏是指由于疏忽或错误造成了程序未能释放掉不再使用的内存的情况。内存泄漏并非指内存在物理上的消失，而是应用程序分配某段内存后，由于设计错误，失去了对该段内存的控制，因而造成了内存的浪费。

内存泄漏的分类：

（1）堆内存泄漏（Heap leak）。对内存指的是程序运行中根据需要分配通过malloc,realloc new等从堆中分配的一块内存，再是完成后必须通过调用对应的free 或者delete 删掉。如果程序的设计的错误导致这部分内存没有被释放，那么此后这块内存将不会被使用，就会产生Heap Leak。

（2）系统资源泄露（Resource Leak）。主要指程序使用系统分配的资源比如Bitmap,handle ,SOCKET等没有使用相应的函数释放掉，导致系统资源的浪费，严重可导致系统效能降低，系统运行不稳定。

（3）没有将基类的析构函数定义为虚函数。当基类指针指向子类对象时，如果基类的析构函数不是virtual，那么子类的析构函数将不会被调用，子类的资源没有正确是释放，因此造成内存泄露。

**3、野指针/悬空指针**

野指针：未初始化的指针。

悬空指针：指向一块曾经保存数据但现在已经无效的内存的指针。

产生的原因：

（1）创建指针变量时，未初始化未NULL，则其指向是随机的，为野指针；

（2）释放了指针变量指向的内存单元，但是没有将指针变量的值重置为NULL，为悬空指针；

（3）指针操作超过了变量类型占用的范围；

避免方法：定义指针变量时，将指针变量初始化为NULL；释放完指针变量指向的内存单元后，将指针变量指向的值设置为NULL。

#### 6. 死锁发生的条件以及如何解决死锁

死锁是指两个或两个以上进程在执行过程中，因争夺资源而造成的下相互等待的现象。死锁发生的四个必要条件如下：

**互斥条件**：进程对所分配到的资源不允许其他进程访问，若其他进程访问该资源，只能等待，直至占有该资源的进程使用完成后释放该资源；

**请求和保持条件**：进程获得一定的资源后，又对其他资源发出请求，但是该资源可能被其他进程占有，此时请求阻塞，但该进程不会释放自己已经占有的资源

**不可剥夺条件**：进程已获得的资源，在未完成使用之前，不可被剥夺，只能在使用后自己释放

**环路等待条件**：进程发生死锁后，必然存在一个进程-资源之间的环形链

解决死锁的方法即破坏上述四个条件之一，主要方法如下：

资源一次性分配，从而剥夺请求和保持条件

可剥夺资源：即当进程新的资源未得到满足时，释放已占有的资源，从而破坏不可剥夺的条件

资源有序分配法：系统给每类资源赋予一个序号，每个进程按编号递增的请求资源，释放则相反，从而破坏环路等待的条件

#### 7.虚拟内存置换的方式

比较常见的内存替换算法有：FIFO，LRU，LFU，LRU-K，2Q。

1、FIFO（先进先出淘汰算法）

思想：最近刚访问的，将来访问的可能性比较大。

实现：使用一个队列，新加入的页面放入队尾，每次淘汰队首的页面，即最先进入的数据，最先被淘汰。

弊端：无法体现页面冷热信息

2、LFU（最不经常访问淘汰算法）

思想：如果数据过去被访问多次，那么将来被访问的频率也更高。

实现：每个数据块一个引用计数，所有数据块按照引用计数排序，具有相同引用计数的数据块则按照时间排序。每次淘汰队尾数据块。

开销：排序开销。

弊端：缓存颠簸。

![](..\images\LFU.png)

3、LRU（最近最少使用替换算法）

思想：如果数据最近被访问过，那么将来被访问的几率也更高。

实现：使用一个栈，新页面或者命中的页面则将该页面移动到栈底，每次替换栈顶的缓存页面。

优点：LRU 算法对热点数据命中率是很高的。

缺陷：

1）缓存颠簸，当缓存（1，2，3）满了，之后数据访问（0，3，2，1，0，3，2，1。。。）。

2）缓存污染，突然大量偶发性的数据访问，会让内存中存放大量冷数据。

4、LRU-K（LRU-2、LRU-3）

思想：最久未使用K 次淘汰算法。

LRU-K 中的K 代表最近使用的次数，因此LRU 可以认为是LRU-1。LRU-K 的主要目的是为了解决LRU 算法“缓存污染”的问题，其核心思想是将“最近使用过1 次”的判断标准扩展为“最近使用过K 次”。

相比LRU，LRU-K 需要多维护一个队列，用于记录所有缓存数据被访问的历史。只有当数据的访问次数达到K 次的时候，才将数据放入缓存。当需要淘汰数据时，LRU-K 会淘汰第K 次访问时间距当前时间最大的数据。

实现：

1）数据第一次被访问，加入到访问历史列表；

2）如果数据在访问历史列表里后没有达到K 次访问，则按照一定规则（FIFO，LRU）淘汰；

3）当访问历史队列中的数据访问次数达到K 次后，将数据索引从历史队列删除，将数据移到缓存队列中，并缓存此数据，缓存队列重新按照时间排序；

4）缓存数据队列中被再次访问后，重新排序；

5）需要淘汰数据时，淘汰缓存队列中排在末尾的数据，即：淘汰“倒数第K 次访问离现在最久”的数据。

针对问题：

LRU-K 的主要目的是为了解决LRU 算法“缓存污染”的问题，其核心思想是将“最近使用过1 次”的判断标准扩展为“最近使用过K 次”。

5、2Q

类似LRU-2。使用一个FIFO 队列和一个LRU 队列。

实现：

1）新访问的数据插入到FIFO 队列；

2）如果数据在FIFO 队列中一直没有被再次访问，则最终按照FIFO 规则淘汰；

3）如果数据在FIFO 队列中被再次访问，则将数据移到LRU 队列头部；

4）如果数据在LRU 队列再次被访问，则将数据移到LRU 队列头部；

5）LRU 队列淘汰末尾的数据。

针对问题：LRU 的缓存污染

弊端：当FIFO 容量为2 时，访问负载是：ABCABCABC 会退化为FIFO，用不到LRU。

#### 8. 互斥锁（mutex）机制，以及互斥锁和读写锁的区别

1、互斥锁和读写锁区别：

互斥锁：mutex，用于保证在任何时刻，都只能有一个线程访问该对象。当获取锁操作失败时，线程会进入睡眠，等待锁释放时被唤醒。

读写锁：rwlock，分为读锁和写锁。处于读操作时，可以允许多个线程同时获得读操作。但是同一时刻只能有一个线程可以获得写锁。其它获取写锁失败的线程都会进入睡眠状态，直到写锁释放时被唤醒。注意：写锁会阻塞其它读写锁。当有一个线程获得写锁在写时，读锁也不能被其它线程获取；写者优先于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）。适用于读取数据的频率远远大于写数据的频率的场合。

互斥锁和读写锁的区别：

1）读写锁区分读者和写者，而互斥锁不区分

2）互斥锁同一时间只允许一个线程访问该对象，无论读写；读写锁同一时间内只允许一个写者，但是允许多个读者同时读对象。

2、Linux 的4 种锁机制：

互斥锁：mutex，用于保证在任何时刻，都只能有一个线程访问该对象。当获取锁操作失败时，线程会进入睡眠，等待锁释放时被唤醒

读写锁：rwlock，分为读锁和写锁。处于读操作时，可以允许多个线程同时获得读操作。但是同一时刻只能有一个线程可以获得写锁。其它获取写锁失败的线程都会进入睡眠状态，直到写锁释放时被唤醒。注意：写锁会阻塞其它读写锁。当有一个线程获得写锁在写时，读锁也不能被其它线程获取；写者优先于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）。适用于读取数据的频率远远大于写数据的频率的场合。

自旋锁：spinlock，在任何时刻同样只能有一个线程访问对象。但是当获取锁操作失败时，不会进入睡眠，而是会在原地自旋，直到锁被释放。这样节省了线程从睡眠状态到被唤醒期间的消耗，在加锁时间短暂的环境下会极大的提高效率。但如果加锁时间过长，则会非常浪费CPU资源。

RCU：即read-copy-update，在修改数据时，首先需要读取数据，然后生成一个副本，对副本进行修改。修改完成后，再将老数据update 成新的数据。使用RCU 时，读者几乎不需要同步开销，既不需要获得锁，也不使用原子指令，不会导致锁竞争，因此就不用考虑死锁问题了。而对于写者的同步开销较大，它需要复制被修改的数据，还必须使用锁机制同步并行其它写者的修改操作。在有大量读操作，少量写操作的情况下效率非常高。